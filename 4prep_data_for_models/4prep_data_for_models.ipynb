{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8224546,
          "sourceType": "datasetVersion",
          "datasetId": 4876350
        },
        {
          "sourceId": 8238800,
          "sourceType": "datasetVersion",
          "datasetId": 4887084
        },
        {
          "sourceId": 8239406,
          "sourceType": "datasetVersion",
          "datasetId": 4887512
        },
        {
          "sourceId": 8239593,
          "sourceType": "datasetVersion",
          "datasetId": 4887627
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install stanza"
      ],
      "metadata": {
        "id": "lykId0sQHlx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "import pandas as pd\n",
        "import stanza\n",
        "import re\n",
        "\n",
        "data = pd.read_csv(\"dataset_cleaned.csv\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-26T19:15:23.999156Z",
          "iopub.execute_input": "2024-04-26T19:15:23.999576Z",
          "iopub.status.idle": "2024-04-26T19:15:24.095665Z",
          "shell.execute_reply.started": "2024-04-26T19:15:23.999547Z",
          "shell.execute_reply": "2024-04-26T19:15:24.094276Z"
        },
        "trusted": true,
        "id": "QixqmdEdHlx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['is_sarcastic'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:15:25.5694Z",
          "iopub.execute_input": "2024-04-26T19:15:25.569832Z",
          "iopub.status.idle": "2024-04-26T19:15:25.579635Z",
          "shell.execute_reply.started": "2024-04-26T19:15:25.569799Z",
          "shell.execute_reply": "2024-04-26T19:15:25.578331Z"
        },
        "trusted": true,
        "id": "MR4MfuZ4HlyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:15:40.710391Z",
          "iopub.execute_input": "2024-04-26T19:15:40.710858Z",
          "iopub.status.idle": "2024-04-26T19:15:40.727746Z",
          "shell.execute_reply.started": "2024-04-26T19:15:40.710815Z",
          "shell.execute_reply": "2024-04-26T19:15:40.726314Z"
        },
        "trusted": true,
        "id": "vFVdaueDHlyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = TweetTokenizer()\n",
        "uk_nlp = stanza.Pipeline(lang='uk', verbose=False)\n",
        "\n",
        "def substitute_user_mentions_and_links(text):\n",
        "    # Regular expression to match user mentions\n",
        "    user_mention_pattern = r'@\\w+'\n",
        "\n",
        "    # Regular expression to match links\n",
        "    link_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "\n",
        "    text = re.sub(user_mention_pattern, '', text)\n",
        "\n",
        "    text = re.sub(link_pattern, '', text)\n",
        "\n",
        "    text = re.sub(r'[a-zA-Z]+', '', text)\n",
        "\n",
        "    return text.lower()\n",
        "\n",
        "def remove_some_punc_numbers(text):\n",
        "    chars_to_remove = r'[\\#\\$\\%\\&\\*\\+\\,\\-\\/\\:\\;\\<\\=\\>\\@\\[\\\\\\]\\^\\_\\{\\|\\}\\~\\d\\.\\â€“]'\n",
        "\n",
        "    result = re.sub(chars_to_remove, '', ' '.join(text))\n",
        "\n",
        "    return result.lower()\n",
        "\n",
        "pattern = r'\\b(\\w+)\\s*\\'\\s*(\\w+)\\b'\n",
        "\n",
        "# join words separated by apostrophe\n",
        "def join_words(match):\n",
        "    return match.group(1) + match.group(2)\n",
        "\n",
        "def lemmatize(text):\n",
        "    lemmas_st = []\n",
        "    for sent in uk_nlp(text).sentences:\n",
        "        for word in sent.words:\n",
        "            lemmas_st.append(word.lemma)\n",
        "    return lemmas_st"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T17:01:23.770394Z",
          "iopub.execute_input": "2024-04-26T17:01:23.770799Z",
          "iopub.status.idle": "2024-04-26T17:01:23.779359Z",
          "shell.execute_reply.started": "2024-04-26T17:01:23.770768Z",
          "shell.execute_reply": "2024-04-26T17:01:23.777836Z"
        },
        "trusted": true,
        "id": "m4ElJp2mHlyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_mod'] = data['text'].apply(substitute_user_mentions_and_links)\n",
        "data['tokenized'] = data['text_mod'].apply(lambda x: tk.tokenize(x))\n",
        "data['tokenized_cleaned'] = data['tokenized'].apply(remove_some_punc_numbers)\n",
        "data['tokenized_cleaned'] = data['tokenized_cleaned'].str.replace(pattern, join_words, regex=True)\n",
        "data['tokenized_cleaned'] = data['tokenized_cleaned'].str.replace(r'\\s+', ' ', regex=True)\n",
        "data['lemmatized'] = data['tokenized_cleaned'].apply(lemmatize)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:17:48.125553Z",
          "iopub.execute_input": "2024-04-26T19:17:48.126119Z",
          "iopub.status.idle": "2024-04-26T20:28:00.287847Z",
          "shell.execute_reply.started": "2024-04-26T19:17:48.126076Z",
          "shell.execute_reply": "2024-04-26T20:28:00.286368Z"
        },
        "trusted": true,
        "id": "HsmXzEC9HlyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"dataset_ready_for_models.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-25T10:06:56.158468Z",
          "iopub.execute_input": "2024-04-25T10:06:56.15895Z",
          "iopub.status.idle": "2024-04-25T10:06:56.603352Z",
          "shell.execute_reply.started": "2024-04-25T10:06:56.158917Z",
          "shell.execute_reply": "2024-04-25T10:06:56.601686Z"
        },
        "trusted": true,
        "id": "6vwKPy4hHlyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating synthetic data from open ai + not sarcastic left"
      ],
      "metadata": {
        "id": "tn3UXLKZHlyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "synth_sarcastic = pd.read_csv(\"synthetic_data_combined.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T17:00:34.701414Z",
          "iopub.execute_input": "2024-04-26T17:00:34.701849Z",
          "iopub.status.idle": "2024-04-26T17:00:34.742823Z",
          "shell.execute_reply.started": "2024-04-26T17:00:34.701806Z",
          "shell.execute_reply": "2024-04-26T17:00:34.741355Z"
        },
        "trusted": true,
        "id": "9wdy82VLHlyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = synth_sarcastic[synth_sarcastic['llm'] == 'openai']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T17:00:51.394533Z",
          "iopub.execute_input": "2024-04-26T17:00:51.394991Z",
          "iopub.status.idle": "2024-04-26T17:00:51.403418Z",
          "shell.execute_reply.started": "2024-04-26T17:00:51.394955Z",
          "shell.execute_reply": "2024-04-26T17:00:51.40236Z"
        },
        "trusted": true,
        "id": "Oag7CsgLHlyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T17:01:13.109717Z",
          "iopub.execute_input": "2024-04-26T17:01:13.11018Z",
          "iopub.status.idle": "2024-04-26T17:01:13.12563Z",
          "shell.execute_reply.started": "2024-04-26T17:01:13.11015Z",
          "shell.execute_reply": "2024-04-26T17:01:13.124209Z"
        },
        "trusted": true,
        "id": "sQt-Ln26Hlyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai['text_mod'] = openai['text'].apply(substitute_user_mentions_and_links)\n",
        "openai['tokenized'] = openai['text_mod'].apply(lambda x: tk.tokenize(x))\n",
        "openai['tokenized_cleaned'] = openai['tokenized'].apply(remove_some_punc_numbers)\n",
        "openai['tokenized_cleaned'] = openai['tokenized_cleaned'].str.replace(pattern, join_words, regex=True)\n",
        "openai['tokenized_cleaned'] = openai['tokenized_cleaned'].str.replace(r'\\s+', ' ', regex=True)\n",
        "openai['lemmatized'] = openai['tokenized_cleaned'].apply(lemmatize)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:11:45.207518Z",
          "iopub.execute_input": "2024-04-26T19:11:45.207947Z",
          "iopub.status.idle": "2024-04-26T19:11:45.213367Z",
          "shell.execute_reply.started": "2024-04-26T19:11:45.207917Z",
          "shell.execute_reply": "2024-04-26T19:11:45.212321Z"
        },
        "trusted": true,
        "id": "WAZh-E0RHlym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T18:40:36.666535Z",
          "iopub.execute_input": "2024-04-26T18:40:36.667005Z",
          "iopub.status.idle": "2024-04-26T18:40:36.675107Z",
          "shell.execute_reply.started": "2024-04-26T18:40:36.666969Z",
          "shell.execute_reply": "2024-04-26T18:40:36.673842Z"
        },
        "trusted": true,
        "id": "vLtzO1rlHlyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_not_sarc = pd.read_csv(\"telegram_not_sarcastic_sample_left.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T18:39:57.138801Z",
          "iopub.execute_input": "2024-04-26T18:39:57.139336Z",
          "iopub.status.idle": "2024-04-26T18:39:57.42598Z",
          "shell.execute_reply.started": "2024-04-26T18:39:57.1393Z",
          "shell.execute_reply": "2024-04-26T18:39:57.4249Z"
        },
        "trusted": true,
        "id": "4nP8jxy-Hlyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "real_not_sarc_sample = real_not_sarc.sample(random_state=42, n=2554)\n",
        "real_not_sarc_sample.rename(columns={'Message': 'text'}, inplace=True)\n",
        "real_not_sarc_sample['text_mod'] = real_not_sarc_sample['text'].apply(substitute_user_mentions_and_links)\n",
        "real_not_sarc_sample['tokenized'] = real_not_sarc_sample['text_mod'].apply(lambda x: tk.tokenize(x))\n",
        "real_not_sarc_sample['tokenized_cleaned'] = real_not_sarc_sample['tokenized'].apply(remove_some_punc_numbers)\n",
        "real_not_sarc_sample['tokenized_cleaned'] = real_not_sarc_sample['tokenized_cleaned'].str.replace(pattern, join_words, regex=True)\n",
        "real_not_sarc_sample['tokenized_cleaned'] = real_not_sarc_sample['tokenized_cleaned'].str.replace(r'\\s+', ' ', regex=True)\n",
        "real_not_sarc_sample['lemmatized'] = real_not_sarc_sample['tokenized_cleaned'].apply(lemmatize)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T18:46:08.373609Z",
          "iopub.execute_input": "2024-04-26T18:46:08.374096Z",
          "iopub.status.idle": "2024-04-26T19:02:45.299212Z",
          "shell.execute_reply.started": "2024-04-26T18:46:08.374056Z",
          "shell.execute_reply": "2024-04-26T19:02:45.297868Z"
        },
        "trusted": true,
        "id": "RI3twQqwHlyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = openai[['text', 'text_mod', 'tokenized','tokenized_cleaned', 'lemmatized']]\n",
        "openai['is_sarcastic'] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:07:27.62799Z",
          "iopub.execute_input": "2024-04-26T19:07:27.628387Z",
          "iopub.status.idle": "2024-04-26T19:07:27.635707Z",
          "shell.execute_reply.started": "2024-04-26T19:07:27.628359Z",
          "shell.execute_reply": "2024-04-26T19:07:27.63458Z"
        },
        "trusted": true,
        "id": "k9lPnk9AHlyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_not_sarc_sample = real_not_sarc_sample[['text', 'text_mod', 'tokenized','tokenized_cleaned', 'lemmatized']]\n",
        "real_not_sarc_sample['is_sarcastic'] = 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:08:25.80677Z",
          "iopub.execute_input": "2024-04-26T19:08:25.807222Z",
          "iopub.status.idle": "2024-04-26T19:08:25.817406Z",
          "shell.execute_reply.started": "2024-04-26T19:08:25.807182Z",
          "shell.execute_reply": "2024-04-26T19:08:25.816146Z"
        },
        "trusted": true,
        "id": "7AG1EIQQHlyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([real_not_sarc_sample, openai]).to_csv(\"synth_openai_sarc_and_not.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T19:10:17.696727Z",
          "iopub.execute_input": "2024-04-26T19:10:17.697158Z",
          "iopub.status.idle": "2024-04-26T19:10:17.914349Z",
          "shell.execute_reply.started": "2024-04-26T19:10:17.697126Z",
          "shell.execute_reply": "2024-04-26T19:10:17.913452Z"
        },
        "trusted": true,
        "id": "0PrFdwyyHlyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEd9J1n_Hlyy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}